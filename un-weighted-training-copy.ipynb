{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339},{"sourceId":7453321,"sourceType":"datasetVersion","datasetId":4338198},{"sourceId":40174,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":33837}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nfrom torchvision import transforms\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\nfrom torch.utils.data import DataLoader, WeightedRandomSampler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiPartDataset(Dataset):\n    def __init__(self, path_to_folders, label_csv, transform):\n        self.meta_data = pd.read_csv(label_csv)\n        self.path_to_folders = path_to_folders\n        self.data = []\n        \n        dx, self.class_labels = pd.factorize(self.meta_data['dx'], sort=True)\n        dx_type, _ = pd.factorize(self.meta_data['dx_type'], sort=True)\n        age, _ = pd.factorize(self.meta_data['age'], sort=True)\n        sex, _ = pd.factorize(self.meta_data['sex'], sort=True)\n        for path in self.path_to_folders:\n            files = os.listdir(path)\n\n            localization, _ = pd.factorize(self.meta_data['localization'], sort=True)\n            for file in sorted(files):\n                idx = self.meta_data['image_id'] == file.split('.')[0]\n                self.data.append((path, file, [dx_type[idx], age[idx], sex[idx], localization[idx]], dx[idx]))\n        \n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.data[idx][0], self.data[idx][1])\n        image = Image.open(img_name)\n        label = self.data[idx][3]\n        attributes = np.array(self.data[idx][2])\n        attributes = torch.from_numpy(attributes.flatten())\n\n        if self.transform:\n            image = self.transform(image)\n        \n        \n        return image, attributes, label[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:45:24.148087Z","iopub.execute_input":"2024-04-26T19:45:24.148716Z","iopub.status.idle":"2024-04-26T19:45:24.160490Z","shell.execute_reply.started":"2024-04-26T19:45:24.148685Z","shell.execute_reply":"2024-04-26T19:45:24.159588Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"folders = [\"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\", \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2\"]\nmeta_csv_file_path = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\"\ntransform = transforms.Compose([\n    transforms.Resize((255, 255)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ndataset = MultiPartDataset(folders, meta_csv_file_path, transform)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:45:27.196342Z","iopub.execute_input":"2024-04-26T19:45:27.197119Z","iopub.status.idle":"2024-04-26T19:45:47.338204Z","shell.execute_reply.started":"2024-04-26T19:45:27.197087Z","shell.execute_reply":"2024-04-26T19:45:47.337428Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n\n# Initialize the VGG model with pre-trained weights\nmodel = models.resnet50(pretrained=True)\nnum_features = model.fc.in_features\nnum_classes = len(torch.unique(torch.tensor(dataset.meta_data['dx'].factorize()[0])))\nmodel.fc = nn.Linear(num_features, num_classes)\nprint(num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:46:46.903560Z","iopub.execute_input":"2024-04-26T19:46:46.904005Z","iopub.status.idle":"2024-04-26T19:46:50.837327Z","shell.execute_reply.started":"2024-04-26T19:46:46.903974Z","shell.execute_reply":"2024-04-26T19:46:50.836463Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:03<00:00, 31.2MB/s]\n","output_type":"stream"},{"name":"stdout","text":"7\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T19:46:55.651531Z","iopub.execute_input":"2024-04-26T19:46:55.652391Z","iopub.status.idle":"2024-04-26T19:46:55.662669Z","shell.execute_reply.started":"2024-04-26T19:46:55.652360Z","shell.execute_reply":"2024-04-26T19:46:55.661855Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def make_weights_for_balanced_classes(dataset):\n    unique_labels = np.unique(dataset.meta_data[\"dx\"])\n    class_counts = {label: 0 for label in unique_labels}\n    \n    for _, _, _, label in dataset.data:\n        class_counts[dataset.class_labels[label][0]] += 1\n        \n    \n    total_samples = len(dataset)\n    weights = [total_samples / class_counts[label] for label in unique_labels.tolist()]\n    \n    return weights\n\nweights = make_weights_for_balanced_classes(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:09:46.942667Z","iopub.execute_input":"2024-04-26T20:09:46.943245Z","iopub.status.idle":"2024-04-26T20:09:47.056670Z","shell.execute_reply.started":"2024-04-26T20:09:46.943214Z","shell.execute_reply":"2024-04-26T20:09:47.055930Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming 'dataset' is already defined\ntrain_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n\n\n#weights = make_weights_for_balanced_classes(dataset)\nsampler = WeightedRandomSampler(weights, len(weights))\n\ntrain_loader = DataLoader(train_data, batch_size=32, sampler=sampler)\nval_loader = DataLoader(val_data, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:13:49.833959Z","iopub.execute_input":"2024-04-26T20:13:49.834753Z","iopub.status.idle":"2024-04-26T20:16:34.395854Z","shell.execute_reply.started":"2024-04-26T20:13:49.834723Z","shell.execute_reply":"2024-04-26T20:16:34.395007Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def compute_accuracy(model, test_loader, loss_fn):\n    model.eval()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    correct, total = 0, 0\n    class_correct = [0] * 7\n    class_total = [0] * 7\n    loss_total = 0\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            loss_total += torch.sum(loss) / 8\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            for i in range(len(predicted)):\n                class_correct[labels[i]] += (predicted[i] == labels[i]).item()\n                class_total[labels[i]] += 1\n            correct += (predicted == labels).sum().item()\n    class_accuracy = [100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(7)]\n    print(class_accuracy)\n\n    return correct / total * 100, loss_total / len(test_loader)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:17:21.979221Z","iopub.execute_input":"2024-04-26T20:17:21.980147Z","iopub.status.idle":"2024-04-26T20:17:21.993654Z","shell.execute_reply.started":"2024-04-26T20:17:21.980112Z","shell.execute_reply":"2024-04-26T20:17:21.992825Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"num_epochs = 20\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    train_correct = 0\n    train_total = 0\n\n    for images, attributes, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        train_total += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n\n    train_accuracy = 100 * train_correct / train_total\n\n    # Validation phase\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n\n    with torch.no_grad():\n        for images, attributes, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * val_correct / val_total\n    print(f'Epoch {epoch+1}, Training Loss: {train_loss/train_total:.4f}, Training Accuracy: {train_accuracy:.2f}%, Validation Loss: {val_loss/val_total:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:17:27.653494Z","iopub.execute_input":"2024-04-26T20:17:27.653858Z","iopub.status.idle":"2024-04-26T20:18:57.262977Z","shell.execute_reply.started":"2024-04-26T20:17:27.653829Z","shell.execute_reply":"2024-04-26T20:18:57.261987Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Epoch 1, Training Loss: 0.2912, Training Accuracy: 0.00%, Validation Loss: 0.0613, Validation Accuracy: 12.53%\nEpoch 2, Training Loss: 0.2384, Training Accuracy: 71.43%, Validation Loss: 0.0578, Validation Accuracy: 30.15%\nEpoch 3, Training Loss: 0.2062, Training Accuracy: 100.00%, Validation Loss: 0.0546, Validation Accuracy: 37.09%\nEpoch 4, Training Loss: 0.1788, Training Accuracy: 100.00%, Validation Loss: 0.0521, Validation Accuracy: 31.20%\nEpoch 5, Training Loss: 0.1783, Training Accuracy: 42.86%, Validation Loss: 0.0516, Validation Accuracy: 22.72%\nEpoch 6, Training Loss: 0.1244, Training Accuracy: 57.14%, Validation Loss: 0.0517, Validation Accuracy: 19.87%\nEpoch 7, Training Loss: 0.1206, Training Accuracy: 85.71%, Validation Loss: 0.0543, Validation Accuracy: 11.78%\nEpoch 8, Training Loss: 0.0698, Training Accuracy: 100.00%, Validation Loss: 0.0573, Validation Accuracy: 9.14%\nEpoch 9, Training Loss: 0.0558, Training Accuracy: 100.00%, Validation Loss: 0.0598, Validation Accuracy: 8.74%\nEpoch 10, Training Loss: 0.0478, Training Accuracy: 100.00%, Validation Loss: 0.0613, Validation Accuracy: 10.43%\nEpoch 11, Training Loss: 0.1743, Training Accuracy: 71.43%, Validation Loss: 0.0618, Validation Accuracy: 13.83%\nEpoch 12, Training Loss: 0.0201, Training Accuracy: 100.00%, Validation Loss: 0.0602, Validation Accuracy: 23.86%\nEpoch 13, Training Loss: 0.0178, Training Accuracy: 100.00%, Validation Loss: 0.0590, Validation Accuracy: 33.30%\nEpoch 14, Training Loss: 0.0288, Training Accuracy: 100.00%, Validation Loss: 0.0583, Validation Accuracy: 40.49%\nEpoch 15, Training Loss: 0.0450, Training Accuracy: 100.00%, Validation Loss: 0.0574, Validation Accuracy: 46.03%\nEpoch 16, Training Loss: 0.1035, Training Accuracy: 85.71%, Validation Loss: 0.0554, Validation Accuracy: 50.87%\nEpoch 17, Training Loss: 0.0439, Training Accuracy: 85.71%, Validation Loss: 0.0551, Validation Accuracy: 52.12%\nEpoch 18, Training Loss: 0.0142, Training Accuracy: 100.00%, Validation Loss: 0.0529, Validation Accuracy: 57.41%\nEpoch 19, Training Loss: 0.0185, Training Accuracy: 100.00%, Validation Loss: 0.0521, Validation Accuracy: 61.36%\nEpoch 20, Training Loss: 0.0483, Training Accuracy: 100.00%, Validation Loss: 0.0522, Validation Accuracy: 62.76%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model\nmodel_path = 'resnet50_model_weighted_random_sampling.h5'\ntorch.save(model.state_dict(), model_path)\nprint(f'Model saved to {model_path}')","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:19:16.462024Z","iopub.execute_input":"2024-04-26T20:19:16.462654Z","iopub.status.idle":"2024-04-26T20:19:16.622933Z","shell.execute_reply.started":"2024-04-26T20:19:16.462623Z","shell.execute_reply":"2024-04-26T20:19:16.622043Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Model saved to resnet50_model_weighted_random_sampling.h5\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load model from vbefore\n# model_path = '/kaggle/working/resnet50_model_skin_cancer_unweighted.h5'\n# model_path = 'resnet50_model_weighted_random_sampling.h5'\nmodel = \"/kaggle/input/resnet_50_skin_chkpt3/pytorch/checkpoint3_resnet_skin/1/ResNet50_checkpoint_3.pth\"\nmodel = models.resnet50(pretrained=False)  # Instantiate the model with the same architecture\nnum_features = model.fc.in_features\nnum_classes = len(torch.unique(torch.tensor(dataset.meta_data['dx'].factorize()[0])))\nmodel.fc = nn.Linear(num_features, num_classes)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.load_state_dict(torch.load(model_path))  # Load the saved weights","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:20:41.257895Z","iopub.execute_input":"2024-04-26T21:20:41.258258Z","iopub.status.idle":"2024-04-26T21:20:41.829036Z","shell.execute_reply.started":"2024-04-26T21:20:41.258228Z","shell.execute_reply":"2024-04-26T21:20:41.828213Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n  warnings.warn(msg)\n","output_type":"stream"},{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"class_labels = list(dataset.class_labels)\n\nclass TestDataset(Dataset):\n    def __init__(self, path_to_img_folder, path_to_csv, transform):\n        self.labels = pd.read_csv(path_to_csv)\n        self.path_to_img_folder = path_to_img_folder\n        self.data = []\n        \n        i = 0\n        for file in sorted(os.listdir(self.path_to_img_folder)):\n            if file[-4:] == \".jpg\":\n                idx = self.labels['image'] == file.split('.')[0]\n                class_name = self.labels[idx].eq(1.0).idxmax(axis=1).values[0].lower()\n                self.data.append((file, class_labels.index(class_name)))\n    \n        self.data = np.array(self.data)\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.path_to_img_folder, self.data[idx][0])\n        image = Image.open(img_name)\n        label = self.data[idx][1]\n\n        if self.transform:\n            image = self.transform(image)\n        \n        return image, torch.tensor(int(label))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:38:53.080693Z","iopub.execute_input":"2024-04-26T20:38:53.081552Z","iopub.status.idle":"2024-04-26T20:38:53.091009Z","shell.execute_reply.started":"2024-04-26T20:38:53.081519Z","shell.execute_reply":"2024-04-26T20:38:53.090040Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"path_to_csv = \"/kaggle/input/isic-2018-task-3/ISIC2018_Task3_Test_GroundTruth/ISIC2018_Task3_Test_GroundTruth/ISIC2018_Task3_Test_GroundTruth.csv\"\npath_to_test_img = \"/kaggle/input/isic-2018-task-3/ISIC2018_Task3_Test_Input/ISIC2018_Task3_Test_Input\"\ntransform = transforms.Compose([\n    transforms.Resize(227),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n])\ntest_dataset = TestDataset(path_to_test_img, path_to_csv, transform)\ntest_loader = DataLoader(test_dataset, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:39:12.109575Z","iopub.execute_input":"2024-04-26T20:39:12.110442Z","iopub.status.idle":"2024-04-26T20:39:13.935358Z","shell.execute_reply.started":"2024-04-26T20:39:12.110409Z","shell.execute_reply":"2024-04-26T20:39:13.934276Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"compute_accuracy(model, test_loader, criterion)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T20:43:29.802019Z","iopub.execute_input":"2024-04-26T20:43:29.802784Z","iopub.status.idle":"2024-04-26T20:43:49.144938Z","shell.execute_reply.started":"2024-04-26T20:43:29.802750Z","shell.execute_reply":"2024-04-26T20:43:49.143949Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"[2.3255813953488373, 49.46236559139785, 39.63133640552996, 0.0, 0.0, 7.040704070407041, 0.0]\n","output_type":"stream"},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"(13.029100529100528, tensor(0.2352, device='cuda:0'))"},"metadata":{}}]},{"cell_type":"code","source":"df = pd.read_csv(path_to_csv)\nclass_counts = df.iloc[:, 1:].sum()\n\nprint(f\"Class counts {class_counts}\")\n\nprint(class_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T04:55:22.181314Z","iopub.execute_input":"2024-04-26T04:55:22.182084Z","iopub.status.idle":"2024-04-26T04:55:22.197642Z","shell.execute_reply.started":"2024-04-26T04:55:22.182053Z","shell.execute_reply":"2024-04-26T04:55:22.196703Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Class counts MEL      171.0\nNV       909.0\nBCC       93.0\nAKIEC     43.0\nBKL      217.0\nDF        44.0\nVASC      35.0\ndtype: float64\n['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import balanced_accuracy_score\ndef computeaccuracy(model, test_loader, loss_fn, class_labels):\n    model.eval()\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    correct, total = 0, 0\n    class_correct = [0] * 7\n    class_total = [0] * 7\n    loss_total = 0\n    all_labels = []\n    all_preds = []\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            loss_total += torch.sum(loss) / 8 \n            _ , predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n        \n\n\n            all_labels.extend(labels.cpu().numpy())\n            all_preds.extend(predicted.cpu().numpy())\n\n            for i in range(len(labels)):\n                label = labels[i].item()\n                pred = predicted[i].item()\n                class_correct[label] += (pred == label)\n                class_total[label] += 1\n\n    label_accuracy = {}\n    class_accuracy = [100 * class_correct[i] / class_total[i] if class_total[i] > 0 else 0 for i in range(7)]\n    print(\"Class-specific Accuracies:\", class_accuracy)\n    for i, acc in enumerate(class_accuracy):\n        label_accuracy[class_labels[i]] = acc\n\n    standard_accuracy = correct / total * 100\n\n    balanced_acc = balanced_accuracy_score(all_labels, all_preds)\n\n\n    return standard_accuracy, balanced_acc, loss_total / len(test_loader), label_accuracy\n\ncomputeaccuracy(model, test_loader, criterion, class_labels)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T21:20:46.983460Z","iopub.execute_input":"2024-04-26T21:20:46.984208Z","iopub.status.idle":"2024-04-26T21:21:05.440410Z","shell.execute_reply.started":"2024-04-26T21:20:46.984177Z","shell.execute_reply":"2024-04-26T21:21:05.439534Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"Class-specific Accuracies: [65.11627906976744, 75.26881720430107, 61.29032258064516, 29.545454545454547, 40.35087719298246, 78.98789878987898, 68.57142857142857]\n","output_type":"stream"},{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"(69.77513227513228,\n 0.5987586827920832,\n tensor(0.1079, device='cuda:0'),\n {'akiec': 65.11627906976744,\n  'bcc': 75.26881720430107,\n  'bkl': 61.29032258064516,\n  'df': 29.545454545454547,\n  'mel': 40.35087719298246,\n  'nv': 78.98789878987898,\n  'vasc': 68.57142857142857})"},"metadata":{}}]}]}