{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30684,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport numpy as np\nimport pandas as pd\nimport torch\nimport os\nfrom torchvision import transforms\nfrom PIL import Image\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:04:34.075223Z","iopub.execute_input":"2024-04-25T20:04:34.075832Z","iopub.status.idle":"2024-04-25T20:04:41.145437Z","shell.execute_reply.started":"2024-04-25T20:04:34.075804Z","shell.execute_reply":"2024-04-25T20:04:41.144657Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class MultiPartDataset(Dataset):\n    def __init__(self, path_to_folders, label_csv, transform):\n        self.meta_data = pd.read_csv(label_csv)\n        self.path_to_folders = path_to_folders\n        self.data = []\n        \n        dx, _ = pd.factorize(self.meta_data['dx'], sort=True)\n        dx_type, _ = pd.factorize(self.meta_data['dx_type'], sort=True)\n        age, _ = pd.factorize(self.meta_data['age'], sort=True)\n        sex, _ = pd.factorize(self.meta_data['sex'], sort=True)\n        for path in self.path_to_folders:\n            files = os.listdir(path)\n\n            localization, _ = pd.factorize(self.meta_data['localization'], sort=True)\n            for file in sorted(files):\n                idx = self.meta_data['image_id'] == file.split('.')[0]\n                self.data.append((path, file, [dx_type[idx], age[idx], sex[idx], localization[idx]], dx[idx]))\n        \n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join(self.data[idx][0], self.data[idx][1])\n        image = Image.open(img_name)\n        label = self.data[idx][3]\n        attributes = np.array(self.data[idx][2])\n        attributes = torch.from_numpy(attributes.flatten())\n\n        if self.transform:\n            image = self.transform(image)\n        \n        \n        return image, attributes, label[0]","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:05:24.112147Z","iopub.execute_input":"2024-04-25T20:05:24.112862Z","iopub.status.idle":"2024-04-25T20:05:24.123597Z","shell.execute_reply.started":"2024-04-25T20:05:24.112830Z","shell.execute_reply":"2024-04-25T20:05:24.122596Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"folders = [\"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\", \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2\"]\nmeta_csv_file_path = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\"\ntransform = transforms.Compose([\n    transforms.Resize((255, 255)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\ndataset = MultiPartDataset(folders, meta_csv_file_path, transform)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:05:27.676888Z","iopub.execute_input":"2024-04-25T20:05:27.677478Z","iopub.status.idle":"2024-04-25T20:05:47.927643Z","shell.execute_reply.started":"2024-04-25T20:05:27.677442Z","shell.execute_reply":"2024-04-25T20:05:47.926815Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"data_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n\n# Initialize the VGG model with pre-trained weights\nmodel = models.vgg16(pretrained=True)\nnum_features = model.classifier[6].in_features\nnum_classes = len(torch.unique(torch.tensor(dataset.meta_data['dx'].factorize()[0])))\nmodel.classifier[6] = nn.Linear(num_features, num_classes)\nprint(num_classes)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:11:57.698612Z","iopub.execute_input":"2024-04-25T20:11:57.698961Z","iopub.status.idle":"2024-04-25T20:11:59.349212Z","shell.execute_reply.started":"2024-04-25T20:11:57.698935Z","shell.execute_reply":"2024-04-25T20:11:59.348141Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"},{"name":"stdout","text":"7\n","output_type":"stream"}]},{"cell_type":"code","source":"# Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:12:05.796318Z","iopub.execute_input":"2024-04-25T20:12:05.796994Z","iopub.status.idle":"2024-04-25T20:12:06.110399Z","shell.execute_reply.started":"2024-04-25T20:12:05.796961Z","shell.execute_reply":"2024-04-25T20:12:06.109408Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming 'dataset' is already defined\ntrain_data, val_data = train_test_split(dataset, test_size=0.2, random_state=42)\n\ntrain_loader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_data, batch_size=32, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:22:38.200934Z","iopub.execute_input":"2024-04-25T20:22:38.201968Z","iopub.status.idle":"2024-04-25T20:24:09.244429Z","shell.execute_reply.started":"2024-04-25T20:22:38.201922Z","shell.execute_reply":"2024-04-25T20:24:09.243571Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"num_epochs = 20\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0.0\n    train_correct = 0\n    train_total = 0\n\n    for images, attributes, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        train_total += labels.size(0)\n        train_correct += (predicted == labels).sum().item()\n\n    train_accuracy = 100 * train_correct / train_total\n\n    # Validation phase\n    model.eval()\n    val_loss = 0.0\n    val_correct = 0\n    val_total = 0\n\n    with torch.no_grad():\n        for images, attributes, labels in val_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * val_correct / val_total\n    print(f'Epoch {epoch+1}, Training Loss: {train_loss/train_total:.4f}, Training Accuracy: {train_accuracy:.2f}%, Validation Loss: {val_loss/val_total:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-04-25T20:50:08.469222Z","iopub.execute_input":"2024-04-25T20:50:08.469912Z","iopub.status.idle":"2024-04-25T21:19:37.772585Z","shell.execute_reply.started":"2024-04-25T20:50:08.469870Z","shell.execute_reply":"2024-04-25T21:19:37.771591Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1, Training Loss: 0.0021, Training Accuracy: 97.84%, Validation Loss: 0.0194, Validation Accuracy: 84.87%\nEpoch 2, Training Loss: 0.0029, Training Accuracy: 96.79%, Validation Loss: 0.0158, Validation Accuracy: 86.52%\nEpoch 3, Training Loss: 0.0015, Training Accuracy: 98.35%, Validation Loss: 0.0191, Validation Accuracy: 85.42%\nEpoch 5, Training Loss: 0.0009, Training Accuracy: 98.99%, Validation Loss: 0.0257, Validation Accuracy: 82.43%\nEpoch 6, Training Loss: 0.0017, Training Accuracy: 98.33%, Validation Loss: 0.0221, Validation Accuracy: 84.52%\nEpoch 7, Training Loss: 0.0012, Training Accuracy: 98.66%, Validation Loss: 0.0187, Validation Accuracy: 85.37%\nEpoch 8, Training Loss: 0.0004, Training Accuracy: 99.70%, Validation Loss: 0.0235, Validation Accuracy: 85.97%\nEpoch 9, Training Loss: 0.0001, Training Accuracy: 99.93%, Validation Loss: 0.0231, Validation Accuracy: 87.22%\nEpoch 10, Training Loss: 0.0001, Training Accuracy: 99.95%, Validation Loss: 0.0250, Validation Accuracy: 86.72%\nEpoch 11, Training Loss: 0.0008, Training Accuracy: 99.21%, Validation Loss: 0.0220, Validation Accuracy: 84.02%\nEpoch 13, Training Loss: 0.0002, Training Accuracy: 99.81%, Validation Loss: 0.0228, Validation Accuracy: 86.82%\nEpoch 14, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 0.0231, Validation Accuracy: 87.37%\nEpoch 15, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 0.0246, Validation Accuracy: 87.22%\nEpoch 16, Training Loss: 0.0007, Training Accuracy: 99.34%, Validation Loss: 0.0202, Validation Accuracy: 87.12%\nEpoch 17, Training Loss: 0.0006, Training Accuracy: 99.50%, Validation Loss: 0.0234, Validation Accuracy: 85.67%\nEpoch 18, Training Loss: 0.0006, Training Accuracy: 99.45%, Validation Loss: 0.0225, Validation Accuracy: 86.57%\nEpoch 20, Training Loss: 0.0000, Training Accuracy: 100.00%, Validation Loss: 0.0238, Validation Accuracy: 87.77%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model\nmodel_path = 'vgg_model_skin_cancer.h5'\ntorch.save(model.state_dict(), model_path)\nprint(f'Model saved to {model_path}')","metadata":{"execution":{"iopub.status.busy":"2024-04-25T21:30:12.797365Z","iopub.execute_input":"2024-04-25T21:30:12.798167Z","iopub.status.idle":"2024-04-25T21:30:13.808074Z","shell.execute_reply.started":"2024-04-25T21:30:12.798118Z","shell.execute_reply":"2024-04-25T21:30:13.807065Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model saved to vgg_model_skin_cancer.h5\n","output_type":"stream"}]}]}